# 2024早春-数据结构实现的回顾

## 序章部分
- popcount的并行实现方式,其中几个关键的数字如何得到
> 首先是MASK模式串，01010101, 001100110011, 模式串的来历需要考虑以下,
> 0串宽度从1, 2, 4, 8, 开始递增, 那么对应$2^{2^k} + 1$乘以模式串就得到 unsigned(-1). 
```C++
MASK(k) = unsigned(-1)/(POW(POW(k)) + 1);
```
> 其次是ROUND计算
```C++
ROUND(n, k) = MASK(k) & n + (n >> POW(k) & MASK(k));
```
> 最后并行计算
```C++
n = ROUND(n, 0);
n = ROUND(n, 1);
n = ROUND(n, 2);
n = ROUND(n, 3);
n = ROUND(n, 4);
```

## Vector/List部分
要点如下所示

- #### 扩容以及缩容的两种均摊复杂度计算

- #### 置乱器如何操作，如何证明其均匀性, 结合rand讨论其可行性
> 1. 首先证明任意序列都是可生成的.
实际上只用考虑: $0, 1, 2, ... , n-1$
可以生成任意序列: $a_0, a_1, a_2, ..., a_{n-1}$
考虑数学归纳法, 显然$n = 1$甚至$n = 2$都是成立的. 
在第一步交换的过程中, 显然可能会出现这样的交换, 导致出现 $0, 1, 2, ... ,n - 1,..., n-2, a_{n-1}$, 接下来只需要利用 $0, 1, 2, ... ,n - 1,..., n-2$, 去生成 $a_0, a_1, a_2, ..., a_{n-2}$, 由归纳是成立的.

> 2. 生成排列中, 每个位置的元素都以$\dfrac1n$的概率选自原向量的任意一个位置, 原向量各个元素出现在新排列中各个位置的概率都是$\dfrac1n$.
对依次交换的元素进行归纳, 首先第一个就位的元素$n-1$显然选自全部向量之中, 那么原向量每个元素出现在这个位置的概率都是$\dfrac1n$. 
假设对于前$k$个都是成立的, 也就是前$k$个就位的元素都是以均等概率选择整个向量
我们考虑, 那么对于第$k+1$个元素, 只需证明这个元素可以均等概率取自原向量. 
原向量的每一个元素, 都有 $(\dfrac1n + \dfrac1n + ... + \dfrac1n) = \dfrac{k}n$的概率出现在先前就位的$k$个元素中, 以上每一个加法针对的就是$k$个位置中的每一个, 那么原向量每个元素都有$1-\dfrac{k}{n}$的概率出现在前$n-k$个秩上, 因此原向
量每个位置的元素都有$( 1-\dfrac{k}{n} )\times \dfrac{1}{n-k} = \dfrac1n$的概率成为这个$k+1$个就位的元素.

> 3. 最后显然, 每个排列的概率实际上是 $\dfrac{1}{n!}$.

> 4. 考虑使用 rand() 的可行性.
实际上对于每一个随机数种子, 都确定了一个随机数序列, rand产生的随机数实际上是介于$[0,2^{15})$的数字, 然后随机数种子实际上只有$2^16$种(参照一种典型实现, seed实际上/65536), 最多确定的随机序列数量仅仅只有不超过$9! = 362880$种, 对于稍微大一点的排列也就无能为力了.


- #### List与Vector的排序方式有哪些,指出更适合哪种
- #####  冒泡排序 L/V
>首先回顾冒泡排序的实现, 这其实是借助了一个标志sorted, 使用while循环进行的, 每次右区间断点-1, 当sorted==false的时候才执行while循环, 这实际上优于单纯的双层for循环的形式, 借助sorted可以提前结束扫描. 
接下来考虑稳定性问题, 升序排列, 考虑交换的原则是 $i < j,\  !(a_i <= a_j)$这实际上保证了相同元素不会被交换, 因此是稳定的, 对于list同样可以实现冒泡排序. 因为是逐一扫描不涉及寻秩访问. 

- #####  插入排序 L/V
>这是一种online排序, 底层实现需要依托search方法, 这个方法主要是查找$\leq e$的最小元素, 或者是$\geq e$的最小元素. 起始假定0位置是有序的, 之后从后面向前面插入, 有序区间也不断扩大, 最后全部有序. 后出现的元素插入到后面, 因此是稳定的排序. 
在List的实现之中search的复杂度是$O(n)$的, 但是Vector之中是有序查找, search复杂度是$O(\log n)$的, 但是插入排序的复杂度出现在, 列表种从前向后扩大有序区间是$O(n)$, 查找$O(n)$, 插入$O(1)$, 对于向量而言, 从前向后扩大有序区间是$O(n)$, 查找$O(\log n)$, 插入$O(n)$.因此复杂度都没有很优秀.

- #####  选择排序 L/V
> 选择排序比较有意思, 选择排序是否是稳定的还要看具体的实现方式; 对于向量而言, 选择排序需要每次选出无序区间的最大的元素, 将其交换到无序区间末尾, 单次选择$O(n)$, 交换$O(1)$, 但是例如序列$1,8,2_1,6,3,2_2$, 将8交换到最后的时候, 实际上已经打乱了$2_1,2_2$的顺序, 这样不再稳定; 如果选择插入的方式而不是交换的方式那么就稳定了, 但这也导致单词选择+插入复杂度$O(n)+O(n)$本质上更多了. 但是对于,列表就不一样了, 列表中可以选择插入的方式, 因此可以是稳定的.


- ##### 归并排序 L/V, List的merge以及mergeSort比较重要
归并排序既可以用向量又可以用列表实现, 实际上可以严格地具有$O(n\log n)$的上界. 其实这也是额外空间换来的. 
首先对于列表而言, 关键操作在于merge操作, 给定区间$[p,p + n), [q, q + m)$的两个列表
``` C++
//前提, 两个列表都是有序的
//有序列表的归并：当前列表中自p起的n个元素，与列表L中自q起的m个元素归并
//应当返回新列表的起始迭代器
template <typename T> 
iterator<T> List<T>::merge( iterator<T> p, rank n,List<T>& L, iterator<T> q, rank m ) {
    //注意这里最后归入p所在的列表
    auto res = p.prev();
    while(m > 0 && q != p){//p!=q的条件比较有意思, 这里保证即使重叠的链表也可以合并
        if(n > 0 && *p <= *q){
            p++;n--;//直接移动即可, 自己不必归入自己, =保证稳定性
        }
        else{
            //将q删除, 插入到当前p的后面, q指针++
            this->insert(p, L.remove(q++));
            m--;
        }
    }
    return res;
}

```

>接下来考虑向量的归并
```C++
//这里考虑的是同一个向量内，两个区间的归并
template <typename T> //对各自有序的[lo, mi)和[mi, hi)做归并
void Vector<T>::merge( rank low, rank mid, rank high ) { // lo < mi < hi
    T* const A = this->elem + low;
    T* const B = new T[mid - low];
    T* const C = this->elem + mid;
    const rank lb = mid - low;
    const rank lc = high - mid;
    const rank la = lb + lc;
    //这里B是一个临时空间，
    for(rank i = 0 ;i < lb ;i++){
        B[i]=A[i];
    }
    //开始归并
    int p{}, q{}, tot{};
    while(p < lb && q < lc){
        if(B[p]<=C[q]){
            A[tot++]=B[p++];
        }else{
            A[tot++]=C[q++];
        }
    }
    //这里实际上并不需要申请整个空间实际上使用O(n/2)的空间
    while(p < lb){
        A[tot++]=B[p++];
    }
    //如果C没有归入那么C自然就位

}

```
> 对比，二者的时空复杂度如何？
向量使用了额外的空间, 实际上向量也可以像列表一样, 但是向量删除插入的复杂度高, 这里其实就是一种使用空间换了时间的方法, 直接向原来的A中赋值.


> - 基数排序以及桶排序见后文

- #### 排序中的cycle问题
> cycle相关的问题是排序需要的最少次数, 以及选择排序.
排序需要的最小次数, 也就是cycle的个数. 选择排序每次选择出最大的一个元素, 然后这个元素就就位了, 会脱离之前所在的cycle, 之前所在的cycle长度-1, 这其实就涉及到一个问题, 可能这个元素本身就就位了, 那么就是无效的交换. 

- #### 排序中的逆序对问题 
>逆序对相关的问题主要是插入排序, 冒泡排序
> - 插入排序
对于e = A[r]的那一轮插入, 向前的关键码比较次数不超过r以及之前的总逆序对个数. 因此全体比较个数不超过全部逆序对个数($T$). 插入的复杂度是 $O(n)$, 比较复杂度是$O(T)$, 因此总复杂度是$O(n+T)$, 实际上往往后者起决定性作用, 这是一种**输入敏感的算法**.
> - 冒泡排序
每次交换一个逆序对, 序列的总逆序对-1, 对于bubblesort而言, 显然交换总次数就是逆序对的个数.
逆序对的个数的上限是$\binom{n}{2}$. 这也就是冒泡排序的时间复杂度上限. 


- #### 基于Vector二分查找的三种方法以及比对

##### 1. 最直接的一种, 三个分支比较
```C++
while(low < high){ // 注意没有这个等号, 最后不可能出现[l,l)才命中的情况, 因为差1的时候在上一步必然命中了
    if(elem[mid] < e){
        左区间[low,mid)
    }else if(elem[mid] > e){
        右区间[mid+1,high)
    }else{
        命中退出
    }
}
return npos;
```
> 此种方法的缺点也比较明显, 首先是常数比较大, 大约是$O(1.5\log n)$; 其次是不能反映失败的位置. 主要考虑成功查找的递推式(失败查找是类似的): 
\[T(h) = [T(h-1) + (2^{h-1} -1) * 1] + [2] + [T(h-1) + (2^{h-1}-1) *2],\\
 = 2T(h-1)+3*2^{h-1} - 1, \  \textbf{for} \  n = 2^h - 1\]

##### 2. 考虑减少一个分支, 两个分支进行查找, 进行区间锁定
```C++
while(high - low > 1){//这种情况不是命中退出, 而是锁定最后的区间
    if(elem[mid] < e){
        左区间[low,mid)
    }else{
        右区间[mid,high)
    }
}

最后命中, 但也不一定命中, 最后锁定[low,low+1), 检查这个是不是e
return elem[low]==e ? low : npos;
```
> 此种方法缺点主要是不能反映失败的位置. 

##### 3. 考虑减少一个分支, 两个分支进行查找, 进行查找位置的锁定
```C++

while(low < high){
    if(elem[mid] < e){
        左区间[low,mid)
    }else{
        右区间[mid+1,high)
    }
}
最后low的位置是大于e的最小秩,
return --low;
```


- #### List与Vector如何实现uniquify与deduplicate

- ##### Vector实现
> - uniquify
对有序向量进行去重, 只需要有一个指针i, 进行加到末尾的操作, 指针j扫描整个向量; 指针i存储的应该是上一个插入的位置, 而非待插入的位置, 如果elem[i]==elem[j], 则继续扫描, 否则, elem[++i]=elem[j]; 

> - dedup
r从rank = 1的位置开始, 每次查找[0,r)中是否有elem[r], 如果有那么删除当前的r, 否则r自增. 

- ##### List实现
> - uniquify
对有序列表进行去重, 只需要两个指针并行扫描, 直接删除即可.

> - dedup
r从rank = 1的位置开始, 每次查找[0,r)中是否有elem[r], 如果有那么删除前面的r, 而不是当前的r, 否则指针位置还要记录


- #### 本次实现List迭代器中需要改善的部分,加入next(), prev(), listnode()接口, 不再使用裸指针, iter.ptr属实答辩写法


## Bitmap部分

- #### 底层实现, 两种方法, 分别优势
>实现关键是如何设置特定bit位
```C++
N = (n + 7) / 8;//上取整
MASK(k) = 0x80 >> (k % 8);
```
>这种方法的劣势是一定要初始化全部变量, 但是有些情况下我们不必初始化全部.
>因此使用循环节进行检查


- #### 埃氏筛, 原理以及优化
>根据素数定理, 可以得到, 小于$n $的素数不会超过$O(\dfrac{n}{\ln n}) = O(\dfrac{n}{\log n})$. 每次从素数开始, 把他的整数倍划掉, 最后剩下的就是素数. 
```C++
Bitmap B(n);
for(int i = 2; i * i <= n ; i++){
    if(!B[i]){
        for(int j = i*i; j <= n ; j += i){
            B.set(j);
        }
    }
}
```
>从$j = i * i$开始是一个对常数的优化, 这是由于$2\times i, 3\times i,4\times i,...,(i-1)\times i$在前面的循环中已经被划掉. 
对时间复杂度的推导 : 
\[ S(n) = \dfrac{n}2 + \dfrac{n}3 + \dfrac{n}5 + ... < \dfrac{n}2 + \dfrac{n}3 + \dfrac{n}4 + ... + \dfrac{n}{\dfrac{n}{\log n}} \\
= O(n\log(\dfrac{n}{\log n})) = O(n\log n) \]

## Stack/Queue部分

- #### 双栈成队均摊复杂度分析
> 考虑起始和终止队列都是空的情况下, 每个元素进队出队的生命周期之中, 都要经历, push, pop, push, pop, 因此均摊复杂度为$O(1)$ .

## BST树
>查找时候有一个_hot, 这一点利用的很好, 无论是空结点还是非空结点, 维护操作时都有父亲节点的引用, 大大遍历了操作. 

## AVL树
>主要是connect34算法的统一非常漂亮, 旋转操作并非难事. 
树插入的时候, 尽管会导致$O(\log n)$的结点失衡, 但是仅仅一次旋转就可以改变, 因为局部子树高度不变; 但是对于删除造作, 尽管只有局部结点失衡, 但是旋转之后会失衡传播$O(\log n)$.

## Skiplist部分
>主要是时间复杂度的问题. 跳转时间复杂度为什么时$O(\log n)$
## Hashtable部分

- #### 实现
##### 冲突与再探测
> - 将间隔为$T$的$M$个关键码插入到桶长为$M$的桶中, 每个关键码大约会与$G = \gcd(M,T)$个关键码冲突. 
$i\times T \mod M \longleftrightarrow i\times t \mod m$共有 $m = \dfrac{M}{G}$个同余类, 每个同余类有$G$个.
实际上a=T,b=0是MAD法(key * a + b)%M的特殊情况, 这种情况下, 保证$G = 1$可以使散列尽可能均匀, 因此这也是为什么要使用素数表长. 




##### 惰性删除
>使用一个标志位进行标志, 标志后认为删除, 这样的话可以保证查找链可以延续, 查找的时候跳过冲突的桶以及惰性删除的桶. 
##### 在散列
>如果装填因子过大, 需要再散列, 如果惰性删除标志过多, 也需要再散列. 

- #### 排序
##### 桶排序 V
>主要是借用hash(key)=key这一操作, 将元素存入散列表中, 再依次读出即可; 当然这种情况只能针对没有哈希冲突的情况, 如果存在冲突只需要采用独立链法即可. 实际上线性的也可以写, 比如区间$[300,400]$映射到$[0,100]$;


##### 基数排序 L
>本质就是分别按照一组关键字$\{k_1, k_2, ..., k_n\}$进行排序, 由于稳定排序的稳定性, 可以得到上一组排序后的相对结果, 在下次排序之后是不变的.一个重要应用就是整数排序.

##### 计数排序 V
>其实就是对桶排序的继续优化, 直接通过遍历计算出该元素最后的rank .

## Heap部分

- #### Brute-Force法建堆
> 每次把最后一个元素当作新插入的元素, 进行上滤操作. 下面回顾其复杂度分析: 
考虑$n = 2^{h+1}- 1$的完全二叉堆的建立, 堆高为$h$, 高度为$h$的结点有$2^h$个, 上滤的操作的复杂度正比于结点高度, 因此只需考虑高度求和
$$S(n) = \sum_{k = 0}^{h} k2^k = \sum_{k = 1}^{h} k2^k = \sum_{i = 1}^{h}\sum_{k=i}^h 2^k = (h-1)2^{h+1}  + 2 = O(n\log n)$$
这个复杂度不算优秀, 二叉堆实际上是一个哈斯图,之确定了偏序关系, 但是这个时间复杂度实际足以确定一个全序关系, 因此暗示着存在着更优秀的方法. 

- #### Floyd法建堆
> 换一种思路, 首先从最后一个内部结点开始, 不断地合并, 一个结点+两个堆 = 一个新堆, 这样可以保证最后合并为一个堆。本质就是，首先从最后一个内部节点开始进行下滤
```C++
LastInner(n) = Parent(n-1) = n/2 -1;
```
> 不断向上进行合并操作, 考虑 $n = 2^{h+1} -1 $的堆, 高度为$h$的结点有$2^h$.但是注意到下滤实际上正比的是深度而不是高度, 因此
$$S(n) = \sum_{k = 1}^{h}k2^{h-k} = \sum_{k = 1}^{h-1}k2^{h-k} = 2^{h+1} - 2- h = O(n)$$

- #### 堆排序 V
>堆排序, 这里主要是指的是完全二叉堆对Vector进行排序, 这里是利用了向量的寻秩访问的特性, 直接利用下标的关系对树进行存储. 注意这是一种 **原地算法.**
>回顾其实现的底层原理, 起始的所有元素被当作堆, 从堆顶取出最大的元素, 放到列表后面部分(这里使用的是swap), 每次取出最大元素, 最后完成排列; swap之后堆顶大概率不能满足堆顶的条件, 因此这个时候进行下滤, 又恢复为堆. 每次下滤$O(\log n)$的复杂度. 最后复杂度显然. 再考虑起始的时候进行建堆, 使用floyd法, 是$O(n)$的复杂度.

